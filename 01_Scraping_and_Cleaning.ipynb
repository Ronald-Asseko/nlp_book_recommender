{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement:\n",
    "    Based on people's books suggestions on Reddit (r/booksuggestions), what are similar books that other people have read/suggested? Using NLP and Deep Learning methods, let's analyze those posts and buil a recommender system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Overview\n",
    "1. Pull data from Reddit posts (r/booksuggestions) between July 25, 2010 and March 30, 2021\n",
    "2. Use adv. NLP methods to analyze data:\n",
    "    - clean the posts, remove special characters\n",
    "    - detect entities on each row\n",
    "    - use cont. skip-grams from Word2Vec for similar words\n",
    "    - create a function that input a post and returns 3 books\n",
    "3. Conclusion and recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals of this notebook\n",
    "In this notebook I pull the reddit posts, put them into a dataframe and clean them for my analysis\n",
    "\n",
    "    Data source:\n",
    "     - Reddit r/booksuggestions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first start by importing the libraries we'll need "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.chunk import ne_chunk, conlltags2tree, tree2conlltags\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets' check our working directory and make sure that everything runs smoothly since this is where we'll be downloading our data to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print working directory\n",
    "# print(f'pwd: {pwd}')\n",
    "\n",
    "# list of files in data folder\n",
    "# print(os.listdir(path='..//data/booksuggestions'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up Subreddit's API and Extracting Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data comes from Reddit, and here we use an API called Pushshift to scrape the posts that we want and set up the parameters for that. Those parameters are the subreddit's name and the max number of posts that we can pull at once. Note that as of March 2021, that max is capped at 100. Then we define a function that will take in the API's URL and the parameters we just created. That function, once called, will first access the website we gave it to, check whether the site works, and print 'Successfully accessed the website (API) provided!' if everything works, otherwise it will print \"Failed... No data has been loaded.\" Our function will then download the posts as a JSON file and put them into a data frame. From those 100 posts, we'll create and use a timestamp for each one and take the earliest to create the next batch of 100 posts going backward until there is nothing left to download. We can also move forward depending on which timeframe we wish to capture. Then it will export the dataset to a local directory and print it each time it does so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating url and params variables\n",
    "url = 'https://api.pushshift.io/reddit/search/submission'\n",
    "\n",
    "# creating params for subreddits posts\n",
    "param_booksuggestions = {\n",
    "    'subreddit': 'booksuggestions', #importing booksuggestions subreddit\n",
    "    'size': 100 #max posts that we can retrieve at once\n",
    "}\n",
    "\n",
    "# define function that takes in url and params based on timestamp (utc) \n",
    "# checks the website link and processes it\n",
    "def pull_reddit_posts(url, params):\n",
    "\n",
    "    res = requests.get(url, params)\n",
    "    if res.status_code == 200:\n",
    "        print('Successfully accessed the website (API) provided!')\n",
    "        df = pd.DataFrame(res.json()['data'])\n",
    "        created_utc = df['created_utc'].min()\n",
    "        params['before'] = created_utc  \n",
    "        print(f\"exporting {params['subreddit']}_{created_utc}\")\n",
    "        df.to_csv(f\"../data/booksuggestions/{params['subreddit']}_{created_utc}.csv\")\n",
    "    else:\n",
    "        print(\"Failed... No data has been loaded.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating url and params variables\n",
    "url = 'https://api.pushshift.io/reddit/search/submission'\n",
    "\n",
    "# creating params for subreddits posts\n",
    "param_booksuggestions = {\n",
    "    'subreddit': 'booksuggestions', #importing booksuggestions subreddit\n",
    "    'size': 100 #max posts that we can retrieve at once\n",
    "}\n",
    "# define function that takes in url and params based on timestamp (utc) \n",
    "# checks the website link and processes it\n",
    "def pull_reddit_posts(url, params):\n",
    "\n",
    "    res = requests.get(url, params)\n",
    "    if res.status_code == 200:\n",
    "        print('Successfully accessed the website (API) provided!')\n",
    "        df = pd.DataFrame(res.json()['data'])\n",
    "        created_utc = df['created_utc'].min()\n",
    "        params['before'] = created_utc  \n",
    "        print(f\"exporting {params['subreddit']}_{created_utc}\")\n",
    "        df.to_csv(f\"../data/booksuggestions/{params['subreddit']}_{created_utc}.csv\")\n",
    "    else:\n",
    "        print(\"Failed... No data has been loaded.\") \n",
    "        \n",
    "#list comp to pull multiple booksuggestions posts \n",
    "# from: Tuesday, March 30,2021 1:22:32PM (epoch 1280093579)\n",
    "# to: Sunday, July 25,2010 2:32:59PM (epoch 1617135752)\n",
    "[f'{pull_reddit_posts(url, param_booksuggestions)} {i}' for i in range(200)]\n",
    "\n",
    "#reimporting the booksuggestions files to create a dataframe\n",
    "for file in files:\n",
    "    booksuggestions_list = [pd.read_csv('../data/booksuggestions/' + \n",
    "                                        file) for file in files \n",
    "                            if file.startswith('booksuggestions_')]\n",
    "\n",
    "#dataframe of booksuggestions\n",
    "booksuggestions_data = pd.concat(booksuggestions_list, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we use a list comprehension to use our newly created function to pull 200 batches. We can run this cell multiple times, depending on how much data we want. Please note that if you try to pull too many batches, more than 200 at the time, which will change based on the subreddit you're pulling from, it can give you an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list comp to pull multiple booksuggestions posts \n",
    "# from: Tuesday, March 30,2021 1:22:32PM (epoch 1280093579)\n",
    "# to: Sunday, July 25,2010 2:32:59PM (epoch 1617135752)\n",
    "[f'{pull_reddit_posts(url, param_booksuggestions)} {i}' for i in range(200)]\n",
    "\n",
    "# creating a file variables where all the data are located\n",
    "files = os.listdir(path = '../data/booksuggestions')\n",
    "\n",
    "# checking the list of files in files variable \n",
    "[file for file in files if i.startswith('booksuggestions_')]\n",
    "\n",
    "# checking the number of files\n",
    "print('How many files do we have?', len(files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the data that we want, lets put them into one single data frame and check out how it looks. We have 109,122 rows and 97 columns. Then we export the final dataset to our data directory before we start cleaning the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#reimporting the booksuggestions files to create a dataframe\n",
    "for file in files:\n",
    "    booksuggestions_list = [pd.read_csv('../data/booksuggestions/' + \n",
    "                                        file) for file in files \n",
    "                            if file.startswith('booksuggestions_')]\n",
    "\n",
    "#dataframe of booksuggestions\n",
    "booksuggestions_data = pd.concat(booksuggestions_list, axis=0)\n",
    "\n",
    "# exporting the data\n",
    "booksuggestions_data.to_csv('../data/booksuggestions/booksuggestions_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many rows and columns do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109122, 97)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many rows and columns do we have?\n",
    "booksuggestions_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data cleaning part starts by reimporting the data, check the columns' names and type and only keep author, title, comment, and number of comments (num_comments). Here is what our data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_richtext</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>author_flair_type</th>\n",
       "      <th>can_mod_post</th>\n",
       "      <th>contest_mode</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>domain</th>\n",
       "      <th>full_link</th>\n",
       "      <th>...</th>\n",
       "      <th>thumbnail_width</th>\n",
       "      <th>view_count</th>\n",
       "      <th>media</th>\n",
       "      <th>link_flair_template_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>secure_media</th>\n",
       "      <th>removed_by</th>\n",
       "      <th>og_description</th>\n",
       "      <th>og_title</th>\n",
       "      <th>media_metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spoggy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1526861857</td>\n",
       "      <td>self.booksuggestions</td>\n",
       "      <td>https://www.reddit.com/r/booksuggestions/comme...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>type2adultdiabeetus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1526857596</td>\n",
       "      <td>self.booksuggestions</td>\n",
       "      <td>https://www.reddit.com/r/booksuggestions/comme...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The69thDuncan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1526856465</td>\n",
       "      <td>self.booksuggestions</td>\n",
       "      <td>https://www.reddit.com/r/booksuggestions/comme...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mrjamiemcc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1526855461</td>\n",
       "      <td>self.booksuggestions</td>\n",
       "      <td>https://www.reddit.com/r/booksuggestions/comme...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FrankenHeart</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1526854114</td>\n",
       "      <td>self.booksuggestions</td>\n",
       "      <td>https://www.reddit.com/r/booksuggestions/comme...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                author author_flair_css_class author_flair_richtext  \\\n",
       "0               Spoggy                    NaN                    []   \n",
       "1  type2adultdiabeetus                    NaN                    []   \n",
       "2        The69thDuncan                    NaN                    []   \n",
       "3           mrjamiemcc                    NaN                    []   \n",
       "4         FrankenHeart                    NaN                    []   \n",
       "\n",
       "  author_flair_text author_flair_type can_mod_post contest_mode created_utc  \\\n",
       "0               NaN              text        False        False  1526861857   \n",
       "1               NaN              text        False        False  1526857596   \n",
       "2               NaN              text        False        False  1526856465   \n",
       "3               NaN              text        False        False  1526855461   \n",
       "4               NaN              text        False        False  1526854114   \n",
       "\n",
       "                 domain                                          full_link  \\\n",
       "0  self.booksuggestions  https://www.reddit.com/r/booksuggestions/comme...   \n",
       "1  self.booksuggestions  https://www.reddit.com/r/booksuggestions/comme...   \n",
       "2  self.booksuggestions  https://www.reddit.com/r/booksuggestions/comme...   \n",
       "3  self.booksuggestions  https://www.reddit.com/r/booksuggestions/comme...   \n",
       "4  self.booksuggestions  https://www.reddit.com/r/booksuggestions/comme...   \n",
       "\n",
       "   ...  thumbnail_width view_count media link_flair_template_id author_id  \\\n",
       "0  ...              NaN        NaN   NaN                    NaN       NaN   \n",
       "1  ...              NaN        NaN   NaN                    NaN       NaN   \n",
       "2  ...              NaN        NaN   NaN                    NaN       NaN   \n",
       "3  ...              NaN        NaN   NaN                    NaN       NaN   \n",
       "4  ...              NaN        NaN   NaN                    NaN       NaN   \n",
       "\n",
       "  secure_media removed_by og_description og_title media_metadata  \n",
       "0          NaN        NaN            NaN      NaN            NaN  \n",
       "1          NaN        NaN            NaN      NaN            NaN  \n",
       "2          NaN        NaN            NaN      NaN            NaN  \n",
       "3          NaN        NaN            NaN      NaN            NaN  \n",
       "4          NaN        NaN            NaN      NaN            NaN  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reimporting the data and dropping cols\n",
    "booksuggestions_data = pd.read_csv('/Users/ronald_asseko_messa/Google Drive/dsir-125-large-files/booksuggestions_data.csv')\n",
    "booksuggestions_data.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis=1, inplace=True)\n",
    "\n",
    "booksuggestions_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# checking what the columns look like and their types\n",
    "booksuggestions_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's filter the columns we want  replace all the missing values with \"[...]\" since our model doesn't handle missing values well. Those missing values typically come from posts with no comment or titles. Once it's done, we check if that transformation worked by counting the number of missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author      0\n",
       "title       0\n",
       "selftext    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select only 3 columns \n",
    "df = booksuggestions_data[['author','title', 'selftext']]\n",
    "\n",
    "# filling missing values\n",
    "df.fillna('[...]', inplace=True)\n",
    "\n",
    "#check for missing values\n",
    "df.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we combine our titles and comments into a single cell for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spoggy</td>\n",
       "      <td>Looking for Horror fiction that explores the u...</td>\n",
       "      <td>I love horror films that delve into the outer ...</td>\n",
       "      <td>Looking for Horror fiction that explores the u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>type2adultdiabeetus</td>\n",
       "      <td>Books that are about or talk about US Army PSYOPS</td>\n",
       "      <td>Psyops, an abbreviation of Psychological Opera...</td>\n",
       "      <td>Books that are about or talk about US Army PSY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The69thDuncan</td>\n",
       "      <td>Looking for new sci-fi</td>\n",
       "      <td>So I read a ton of sci-fi and struggle to find...</td>\n",
       "      <td>Looking for new sci-fiSo I read a ton of sci-f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                author                                              title  \\\n",
       "0               Spoggy  Looking for Horror fiction that explores the u...   \n",
       "1  type2adultdiabeetus  Books that are about or talk about US Army PSYOPS   \n",
       "2        The69thDuncan                             Looking for new sci-fi   \n",
       "\n",
       "                                            selftext  \\\n",
       "0  I love horror films that delve into the outer ...   \n",
       "1  Psyops, an abbreviation of Psychological Opera...   \n",
       "2  So I read a ton of sci-fi and struggle to find...   \n",
       "\n",
       "                                                text  \n",
       "0  Looking for Horror fiction that explores the u...  \n",
       "1  Books that are about or talk about US Army PSY...  \n",
       "2  Looking for new sci-fiSo I read a ton of sci-f...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine title and selftext columns\n",
    "df['text'] = df['title'] + df['selftext']\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have a single cell on each row, we clean them by removing the newline escape sequences (“\\n”) and output the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>selftext</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spoggy</td>\n",
       "      <td>Looking for Horror fiction that explores the u...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I love horror films that delve into the outer ...</td>\n",
       "      <td>Looking for Horror fiction that explores the u...</td>\n",
       "      <td>Looking for Horror fiction that explores the u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>type2adultdiabeetus</td>\n",
       "      <td>Books that are about or talk about US Army PSYOPS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Psyops, an abbreviation of Psychological Opera...</td>\n",
       "      <td>Books that are about or talk about US Army PSY...</td>\n",
       "      <td>Books that are about or talk about US Army PSY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The69thDuncan</td>\n",
       "      <td>Looking for new sci-fi</td>\n",
       "      <td>10.0</td>\n",
       "      <td>So I read a ton of sci-fi and struggle to find...</td>\n",
       "      <td>Looking for new sci-fiSo I read a ton of sci-f...</td>\n",
       "      <td>Looking for new sci-fiSo I read a ton of sci-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mrjamiemcc</td>\n",
       "      <td>Recommend me my very first book to read</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Being honest. I have never read a book out of ...</td>\n",
       "      <td>Recommend me my very first book to readBeing h...</td>\n",
       "      <td>Recommend me my very first book to readBeing h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FrankenHeart</td>\n",
       "      <td>Started a book club. Suggestions?</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Somehow I became the age of a person that star...</td>\n",
       "      <td>Started a book club. Suggestions?Somehow I bec...</td>\n",
       "      <td>Started a book club. Suggestions?Somehow I bec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                author                                              title  \\\n",
       "0               Spoggy  Looking for Horror fiction that explores the u...   \n",
       "1  type2adultdiabeetus  Books that are about or talk about US Army PSYOPS   \n",
       "2        The69thDuncan                             Looking for new sci-fi   \n",
       "3           mrjamiemcc            Recommend me my very first book to read   \n",
       "4         FrankenHeart                  Started a book club. Suggestions?   \n",
       "\n",
       "  num_comments                                           selftext  \\\n",
       "0          5.0  I love horror films that delve into the outer ...   \n",
       "1          0.0  Psyops, an abbreviation of Psychological Opera...   \n",
       "2         10.0  So I read a ton of sci-fi and struggle to find...   \n",
       "3          4.0  Being honest. I have never read a book out of ...   \n",
       "4         19.0  Somehow I became the age of a person that star...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Looking for Horror fiction that explores the u...   \n",
       "1  Books that are about or talk about US Army PSY...   \n",
       "2  Looking for new sci-fiSo I read a ton of sci-f...   \n",
       "3  Recommend me my very first book to readBeing h...   \n",
       "4  Started a book club. Suggestions?Somehow I bec...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  Looking for Horror fiction that explores the u...  \n",
       "1  Books that are about or talk about US Army PSY...  \n",
       "2  Looking for new sci-fiSo I read a ton of sci-f...  \n",
       "3  Recommend me my very first book to readBeing h...  \n",
       "4  Started a book club. Suggestions?Somehow I bec...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a function to remove special chars and numbers\n",
    "def clean_text_simple(df, text, clean_text):\n",
    "    df[clean_text] = df[text].astype(str)\n",
    "    df[clean_text] = df[clean_text].apply(lambda elem: re.sub(r\"\\n\", \"; \", elem))  \n",
    "    \n",
    "    return df\n",
    "\n",
    "# applying the clean_text_simple to my text\n",
    "df = clean_text_simple(df, 'text', 'clean_text')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's finally check our file's path and export our latest dataframe. Note that I'm using the \"to_pickle\" method to export the dataframe instead of the \"to_csv\". This allows us to maintain the dataframe in its original form, espacially for words vectors to stay the same and not a list, which is what \"to_csv\" does with tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check file path\n",
    "os.listdir(path='/Users/ronald_asseko_messa/Google Drive/dsir-125-large-files/')\n",
    "\n",
    "# exporting df as a pickle file \n",
    "df.to_pickle('/Users/ronald_asseko_messa/Google Drive/dsir-125-large-files/booksuggestions_clean_df.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
